<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="SceneEval: Evaluating Semantic Coherence in Text-Conditioned 3D Indoor Scene Synthesis">
  <meta name="keywords" content="SceneEval, evaluation, 3D, indoor scene generation, indoor scene synthesis, text-conditioned">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <title>SceneEval: Evaluating Semantic Coherence in Text-Conditioned 3D Indoor Scene Synthesis</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-1THMCYG0RF"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-1THMCYG0RF');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">
              SceneEval: Evaluating Semantic Coherence in <br> Text-Conditioned 3D Indoor Scene Synthesis
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://iv-t.github.io/">Hou In Ivan Tam</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://houip.github.io/portfolio/">Hou In Derek Pun</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://atwang16.github.io/">Austin T. Wang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                  <a href="https://angelxuanchang.github.io/">Angel X. Chang</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="https://msavva.github.io/">Manolis Savva</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Simon Fraser University,</span>
              <span class="author-block"><sup>2</sup>Alberta Machine Intelligence Institute (Amii)</span>
            </div>
            <!-- <div class="is-size-5 publication-authors">
              <span class="author-block" style="color:#a771ac"></span>
            </div> -->

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <!-- <span class="link-block">
                  <a href=""
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span> -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2503.14756" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <!-- <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span> -->
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/3dlg-hcvc/SceneEval" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Released!)</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                <a href="https://github.com/3dlg-hcvc/SceneEval/releases" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Video -->
  <section class="section">
    <div class="container is-max-desktop">
      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <!-- <h2 class="title is-3">Video</h2> -->
          <!-- <div class="publication-video">
            <iframe src="" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div> -->
        </div>
      </div>
      <!--/ Paper video. -->
    </div>  
  </section>

  <!-- Abstract -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">

        <div class="column is-full-width is-large">
          <div class="column has-text-centered">

            <div class="center-container">
              <h2 class="title is-3">Abstract</h2>
            </div>

            <div class="content has-text-justified mt-4">
              <p>
                Despite recent advances in text-conditioned 3D indoor scene generation, there remain gaps in the evaluation of these methods.
                Existing metrics primarily assess the realism of generated scenes by comparing them to a set of ground-truth scenes, often overlooking alignment with the input text &mdash; a critical factor in determining how effectively a method meets user requirements.
              </p>
              <p>
                We present SceneEval, an evaluation framework designed to address this limitation.
                SceneEval includes metrics for both explicit user requirements, such as the presence of specific objects and their attributes described in the input text, and implicit expectations, like the absence of object collisions, providing a comprehensive assessment of scene quality.
                To facilitate evaluation, we introduce SceneEval-100, a dataset of scene descriptions with annotated ground-truth scene properties.
              </p>
              <p>
                We evaluate recent scene generation methods using SceneEval and demonstrate its ability to provide detailed assessments of the generated scenes, highlighting strengths and areas for improvement across multiple dimensions.
                Our results show that current methods struggle at generating scenes that meet user requirements, underscoring the need for further research in this direction.
              </p>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Challenges -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <div class="center-container">
              <h3 class="title is-3">Challenges</h3>
            </div>
            <p>
              Scene synthesis faces two primary challenges: adhering to explicit user requirements and meeting implicit expectations,
              such as physical plausibility, which users often assume but do not explicitly specify. As shown the figure below, both are 
              crucial for practical applications.
            </p>
            <figure class="image">
              <img src="./static/images/explicit_implicit.png" alt="Explicit vs. Implicit Requirements" style="width: 100%; max-width: 800px;">
            </figure>
          </div>
        </div> 
      </div>  
    </div> 
  </section>

  <!-- Overview -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <div class="center-container">
              <h3 class="title is-3">Overview</h3>
            </div>
            <p>
              Given a generated scene and its corresponding annotated properties,
              SceneEval first matches object instances in the scene to the annotated categories.
              It then evaluates the scene on a comprehensive set of fidelity and plausibility metrics.
            </p>
            <figure class="image">
              <img src="./static/images/overview.png" alt="Overview" style="width: 100%; max-width: 800px;">
            </figure>
          </div>
        </div> 
      </div>  
    </div> 
  </section>

  <!-- Annotation -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <div class="center-container">
              <h3 class="title is-3">Dataset: SceneEval-500</h3>
            </div>
            <p>
              To facilitate evaluation, we introduce SceneEval-500,
              a dataset of scene descriptions with annotations on the expected scene properties.
              SceneEval-500 contains 500 scene descriptions covering ten room types:
              bedroom, living room, dining room, playroom, gaming room, kitchen, bathroom, basement, den, and office.
              We define three difficulty levels for the scene descriptions &mdash; easy, medium, and hard &mdash;
              based on the complexity of the descriptions in terms of the number of objects specified.
              The figure below shows an example entry of medium difficulty in SceneEval-500.
              The scene description describes a basement room, a rarely-seen type in existing datasets.
              The annotation includes the expected scene properties, such as number of objects, specified in the text.
            </p>
            <figure class="image">
              <img src="./static/images/annotation.png" alt="Annotation" style="width: 100%; max-width: 800px;">
            </figure>
          </div>
        </div> 
      </div>  
    </div> 
  </section>

  <!-- Results -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <div class="center-container">
              <h3 class="title is-3">Results</h3>
            </div>
            <p>
               Examples of scenes generated using text descriptions in SceneEval-500 and the corresponding evaluation results using SceneEval.
               Our dataset has scene descriptions with annotations of three difficulty levels: easy, medium, and hard.
               SceneEval provides a comprehensive evaluation of the generated scenes on fidelity and plausibility.
            </p>
            <figure class="image">
              <img src="./static/images/results.png" alt="Results" style="width: 100%; max-width: 800px;">
            </figure>
          </div>
        </div> 
      </div>  
    </div> 
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
      @article{tam2025sceneeval,
          title = {{SceneEval}: Evaluating Semantic Coherence in Text-Conditioned {3D} Indoor Scene Synthesis},
          author = {Tam, Hou In Ivan and Pun, Hou In Derek and Wang, Austin T. and Chang, Angel X. and Savva, Manolis},
          year = {2025},
          eprint = {2503.14756},
          archivePrefix = {arXiv}
      }
      </code></pre>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">Acknowledgements</h2>
      <p>
        This work was funded in part by the Sony Research Award Program, a CIFAR AI Chair, a Canada Research Chair, NSERC Discovery Grants, and enabled by support from the <a href="https://alliancecan.ca/">Digital Research Alliance of Canada</a>.
        We thank Nao Yamato, Yotaro Shimose, and other members on the Sony team for their feedback.
        We also thank Qirui Wu, Xiaohao Sun, and Han-Hung Lee for helpful discussions.
      </p>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
              The template is borrowed from <a href="https://nerfies.github.io/">Nerfies</a>.
              Please check out their great work if you find it helpful as well.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
